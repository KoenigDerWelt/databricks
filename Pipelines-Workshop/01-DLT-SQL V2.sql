-- Databricks notebook source
-- MAGIC %md-sandbox 
-- MAGIC
-- MAGIC ## Bronze layer: incrementally ingest data leveraging Databricks Autoloader
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC Raw data is available at cloud object storage at three different locations:
-- MAGIC * historic data from the public lending club data set
-- MAGIC * actual streaming data generated by another notebook 
-- MAGIC * lookup data is coming from a Delta Table
-- MAGIC
-- MAGIC Autoloader simplifies the ingestion, including schema inference, schema evolution while being able to scale to millions of incoming files. 
-- MAGIC
-- MAGIC Autoloader is available in SQL using the `cloud_files` function and can be used with a variety of format (json, csv, avro...):
-- MAGIC
-- MAGIC
-- MAGIC #### STREAMING LIVE TABLE 
-- MAGIC Defining tables as `STREAMING` will guarantee that you only incrementally consume new incoming data. See the [documentation](https://docs.databricks.com/data-engineering/delta-live-tables/delta-live-tables-incremental-data.html) for more details

-- COMMAND ----------

CREATE STREAMING LIVE TABLE BZ_raw_txs
  COMMENT "New raw loan data incrementally ingested from cloud object storage landing zone"
AS SELECT * FROM cloud_files('/demo/frank/landing', 'json')

-- COMMAND ----------

CREATE STREAMING LIVE TABLE BZ_reference_loan_stats
  COMMENT "Raw historical transactions"
AS SELECT * FROM cloud_files('/databricks-datasets/lending-club-loan-stats/LoanStats_*', 'csv')

-- COMMAND ----------

CREATE MATERIALIZED VIEW ref_accounting_treatment
  COMMENT "Lookup mapping for accounting codes"
AS SELECT * FROM delta.`/demo/frank/ref_accounting_treatment/`

-- COMMAND ----------

-- MAGIC %md-sandbox 
-- MAGIC
-- MAGIC ## Silver layer: joining tables while ensuring data quality
-- MAGIC
-- MAGIC
-- MAGIC Once the bronze layer is defined, we'll create the sliver layers for joining data. Note that bronze tables are referenced using the keyword `LIVE`. 
-- MAGIC
-- MAGIC To consume only incremental changes from the Bronze layer like `BZ_raw_txs`, we'll be using the `stream` keyword: `stream(LIVE.BZ_raw_txs)`
-- MAGIC
-- MAGIC DLT handles housekeeping such as compaction for us.
-- MAGIC
-- MAGIC #### Expectations
-- MAGIC Expectations (`CONSTRAINT <name> EXPECT <condition>`) enforce and track data quality. See the [documentation](https://docs.databricks.com/data-engineering/delta-live-tables/delta-live-tables-expectations.html) for more details

-- COMMAND ----------

CREATE STREAMING LIVE TABLE SV_cleaned_new_txs (
  CONSTRAINT `Payments should be this year`  EXPECT (next_payment_date > date('2020-12-31')),
  CONSTRAINT `Balance should be positive`    EXPECT (balance > 0 AND arrears_balance > 0) ON VIOLATION DROP ROW,
  CONSTRAINT `Cost center must be specified` EXPECT (cost_center_code IS NOT NULL) ON VIOLATION FAIL UPDATE
  
)
  COMMENT "Livestream of new transactions, cleaned and compliant"
AS SELECT txs.*, rat.id as accounting_treatment FROM stream(LIVE.BZ_raw_txs) txs
  INNER JOIN live.ref_accounting_treatment rat ON txs.accounting_treatment_id = rat.id

-- COMMAND ----------

CREATE MATERIALIZED VIEW SV_historical_txs
  COMMENT "Historical loan transactions"
AS SELECT a.* FROM LIVE.BZ_reference_loan_stats a
  INNER JOIN LIVE.ref_accounting_treatment b USING (id)

-- COMMAND ----------

-- MAGIC %md-sandbox 
-- MAGIC
-- MAGIC ## Gold layer
-- MAGIC
-- MAGIC
-- MAGIC Our last step is to implement the Gold Layer.
-- MAGIC
-- MAGIC These tables will be requested at scale using a DWH (serverless SQL Endpoint), we'll add Zorder at the table level to ensure faster queries using `pipelines.autoOptimize.zOrderCols`, and DLT will handle it.

-- COMMAND ----------

CREATE MATERIALIZED VIEW GL_total_loan_balances_1
  COMMENT "Combines historical and new loan data for unified rollup of loan balances"
  TBLPROPERTIES ("pipelines.autoOptimize.zOrderCols" = "location_code")
AS SELECT sum(revol_bal)  AS bal, addr_state   AS location_code FROM live.SV_historical_txs  GROUP BY addr_state
  UNION SELECT sum(balance) AS bal, country_code AS location_code FROM live.SV_cleaned_new_txs GROUP BY country_code

-- COMMAND ----------

CREATE MATERIALIZED VIEW GL_total_loan_balances_2
  COMMENT "Combines historical and new loan data for unified rollup of loan balances"
AS SELECT sum(revol_bal)  AS bal, addr_state   AS location_code FROM live.SV_historical_txs  GROUP BY addr_state
  UNION SELECT sum(balance) AS bal, country_code AS location_code FROM live.SV_cleaned_new_txs GROUP BY country_code
